{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeTr11Ec6e4u1faTiJjTm3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"BypeSBleZBuM"},"outputs":[],"source":["import numpy as np\n","\n","y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","t = np.array([0,      0,   1,   0,    0,   0,   0,   0,   0,   0]) # 정답은 2라는 이야기 이다. 클래스의 개수만큼 One Hot Encoding이 되어있는 상태"]},{"cell_type":"markdown","source":["# 평균 제곱 오차 ( Mean Squared Error )\n","신경망에서의 MSE\n","$$\n","MSE = \\frac{1}{2}\\sum_k(y_k-t_k)^2\n","$$\n","\n","인간이 신경망을 공부할 때 사용하는 공부용 MSE 입니다..\n","\n","* $y_k$ : 신경망의 예측값 햇y\n","* $t_k$ : 정답 레이블 target\n","* $k$ : 출력층의 뉴런 개수\n","  * `강아지, 고양이, 말을 예측 하면` $k$는 3 - `클래스는 [0, 1, 2]`\n","  * MNIST 손글씨 데이터 셋이면 $k$는 10 - `클래스는 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`\n","\n","----------\n","* 보통 신경망에서는 `MSE`를 잘 쓰지 않고 `Cross Entropy Error`를 활용\n","  * `MSE`는 신경망으로 회귀를 할 때 많이 사용\n","* `MSE`를 배우는 이유는 말 그대로 `loss`에 대한 이해를 하기 위함\n","* `MSE`는 신경망을 우리가 공부 할 때 개념을 익히는 데에 좋다. ( 실무에서는 사용 잘 안한다. )\n","* 정상적인 $\\frac{1}{n}$을 사용하지 않고 $\\frac{1}{2}$을 사용한 이유는\n","  * `MSE`를 미분 했을 때 남는게 순수한 오차라고 할 수 있는 $(y-t)$만 남기 때문에 (정확한 설명은 아님)"],"metadata":{"id":"j_J2JDAtZG2B"}},{"cell_type":"code","source":["# 각 클래스 별 순수한 오차\n","y-t"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpvFHIj0ZeeD","executionInfo":{"status":"ok","timestamp":1668668733849,"user_tz":-540,"elapsed":567,"user":{"displayName":"한슬기","userId":"16033710566970915474"}},"outputId":"a046b478-84bc-4b8e-b9ff-3bb581a91852"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.1 ,  0.05, -0.4 ,  0.  ,  0.05,  0.1 ,  0.  ,  0.1 ,  0.  ,\n","        0.  ])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# mse(sse)\n","0.5 * np.sum((y-t)**2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ay0d_OTaC5p","executionInfo":{"status":"ok","timestamp":1668668773070,"user_tz":-540,"elapsed":3,"user":{"displayName":"한슬기","userId":"16033710566970915474"}},"outputId":"eb4b8d20-5887-49d7-df8d-bbcbc746378b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.09750000000000003"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# MSE를 사용해서 손실값(Loss값)확인\n","def mean_squared_error(y, t):\n","  return 0.5 * np.sum((y-t)**2)"],"metadata":{"id":"TWwv-ZmxaMvF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.6) : {:.3f}\".format(mean_squared_error(y, t)))\n","\n","y = np.array([0.1, 0.05, 0.8, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 80%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.8) : {:.3f}\".format(mean_squared_error(y, t)))\n","\n","y = np.array([0.7, 0.05, 0.1 , 0.0, 0.05, 0.0, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 10%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.1) : {:.3f}\".format(mean_squared_error(y, t)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NO-bszIfaYzw","executionInfo":{"status":"ok","timestamp":1668668866992,"user_tz":-540,"elapsed":3,"user":{"displayName":"한슬기","userId":"16033710566970915474"}},"outputId":"b48e8a26-6373-4c16-c7a4-1a6ee2b1b8a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["정답을 2로 추정했을 때의 MSE값(0.6) : 0.098\n","정답을 2로 추정했을 때의 MSE값(0.8) : 0.027\n","정답을 2로 추정했을 때의 MSE값(0.1) : 0.657\n"]}]},{"cell_type":"markdown","source":["# 교차 엔트로피 오차( Cross Entropy Error )\n","$$\n","CEE = -\\sum_{k}t_k\\log{y_k}\n","$$\n","\n","* $t_k$는 `One Hot Encoding`이 되어있는 상태\n","* $k$는 클래스의 개수\n","* 정답 레이블의 소프트맥스의 결과가 0.6이면 $-\\log{0.6}$을 구한것과 똑같다."],"metadata":{"id":"5sGnFqPFajpN"}},{"cell_type":"code","source":["def cross_entropy_error(y,t):\n","  delta = 1e-7  # 0.0000001\n","  return -np.sum( t * np.log(y + delta))\n","\n","  # delta는 log0이 나오는걸 방지해주려고 넣어준 아주작은값."],"metadata":{"id":"pob99BgndnGC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["t = np.array([0, 0, 1,   0,    0,   0,   0,   0,   0,   0]) # 정답은 2\n","\n","y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.6) : {:.3f}\".format(cross_entropy_error(y, t)))\n","\n","y = np.array([0.1, 0.05, 0.8, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 80%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.8) : {:.3f}\".format(cross_entropy_error(y, t)))\n","\n","y = np.array([0.7, 0.05, 0.1 , 0.0, 0.05, 0.0, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 10%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.1) : {:.3f}\".format(cross_entropy_error(y, t)))\n","\n","# 잘못된 예측에 대해서 훨씬 큰 loss를 나타냄. 극단적으로 바뀜!!\n","# mse보다 cee가 잘못된 loss를 더 빨리 캐치가능.\n","# 잘못되면 잘못될수록 극단적인 error를 나타내줌"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUfhIduuebAH","executionInfo":{"status":"ok","timestamp":1668669936830,"user_tz":-540,"elapsed":3,"user":{"displayName":"한슬기","userId":"16033710566970915474"}},"outputId":"29e189a6-856d-4d37-c82f-3361ab83a418"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["정답을 2로 추정했을 때의 CEE값(0.6) : 0.511\n","정답을 2로 추정했을 때의 CEE값(0.8) : 0.223\n","정답을 2로 추정했을 때의 CEE값(0.1) : 2.303\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"vJw3xNG5epCV"},"execution_count":null,"outputs":[]}]}